{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0FQnJJC1S-oi",
      "metadata": {
        "id": "0FQnJJC1S-oi"
      },
      "source": [
        "# RAG pipeline with Chroma, Sentence-Transformers, and FLAN-T5 (Colab-ready)\n",
        "\n",
        "This Colab notebook implements:\n",
        "- OCR-aware PDF extraction (handles flattened PDFs) using `pdfplumber` + `pytesseract`.\n",
        "- Text extraction from DOCX and images.\n",
        "- Chunking and per-document JSON export.\n",
        "- Embeddings with `sentence-transformers` (recommended: `all-mpnet-base-v2`).\n",
        "- Vector storage in Chroma (local persistent folder).\n",
        "- Retrieval (query → embedding → top-K).\n",
        "- RAG answer synthesis using `google/flan-t5-base`.\n",
        "- Optional exact-span extraction using a QA model.\n",
        "\n",
        "**How to use**\n",
        "1. Open this notebook in Google Colab.\n",
        "2. (Optional) Change runtime to GPU for faster generation: Runtime → Change runtime type → GPU.\n",
        "3. Run cells sequentially. Upload files when prompted (or mount Google Drive and modify paths).\n",
        "4. Use the `rag_answer` function to ask questions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "-OiwxioCS-ok",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OiwxioCS-ok",
        "outputId": "a2c4e2d3-67b4-41f3-a793-9832a241e07c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.4/132.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.5_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Selecting previously unselected package poppler-utils.\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.12_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.12) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.12) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (Colab)\n",
        "!pip install -q sentence-transformers chromadb pdfplumber python-docx pytesseract pillow transformers accelerate sentencepiece\n",
        "# install tesseract binary (Colab / Debian) and poppler-utils for PDF rasterization\n",
        "!apt-get update -qq && apt-get install -y -qq tesseract-ocr libtesseract-dev poppler-utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a5rxZ48MS-ok",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5rxZ48MS-ok",
        "outputId": "5b005fa3-e107-4feb-9ff6-70d58d7960b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding model: all-mpnet-base-v2\n",
            "Generation model: google/flan-t5-base\n",
            "DB_DIR: /content/chroma_db\n"
          ]
        }
      ],
      "source": [
        "# Imports, paths, and settings\n",
        "import os, json, uuid\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Text extraction libs\n",
        "import pdfplumber, docx\n",
        "from PIL import Image, ImageFilter, ImageOps\n",
        "import pytesseract\n",
        "\n",
        "# Embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Chroma\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "\n",
        "# Generation & QA\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "import torch\n",
        "\n",
        "# Folders\n",
        "DB_DIR = \"/content/chroma_db\"\n",
        "JSON_OUTPUT_DIR = \"/content/doc_jsons\"\n",
        "os.makedirs(DB_DIR, exist_ok=True)\n",
        "os.makedirs(JSON_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Embedding model (choose accuracy vs speed)\n",
        "EMBEDDING_MODEL_NAME = \"all-mpnet-base-v2\"   # recommended for accuracy\n",
        "# EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"  # alternative (faster)\n",
        "\n",
        "# Generation model (RAG fusion / answer synthesis)\n",
        "GEN_MODEL_NAME = \"google/flan-t5-base\"  # use GPU for larger models\n",
        "\n",
        "# QA span-extraction model (optional)\n",
        "QA_MODEL_NAME = \"deepset/roberta-base-squad2\"\n",
        "\n",
        "# Tesseract settings\n",
        "pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\"  # colab default\n",
        "OCR_LANG = \"eng\"\n",
        "TESSERACT_COMMON_CONFIG = f\"--oem 1 --psm 6 -l {OCR_LANG}\"\n",
        "\n",
        "print(\"Embedding model:\", EMBEDDING_MODEL_NAME)\n",
        "print(\"Generation model:\", GEN_MODEL_NAME)\n",
        "print(\"DB_DIR:\", DB_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "OggH3Sb3S-ol",
      "metadata": {
        "id": "OggH3Sb3S-ol"
      },
      "outputs": [],
      "source": [
        "# OCR-aware PDF extractor and helpers\n",
        "\n",
        "def preprocess_pil_image_for_ocr(pil_img):\n",
        "    img = pil_img.convert(\"L\")\n",
        "    img = ImageOps.autocontrast(img, cutoff=1)\n",
        "    img = img.filter(ImageFilter.MedianFilter(size=3))\n",
        "    return img\n",
        "\n",
        "def extract_text_from_pdf(pdf_path, ocr_if_needed=True, min_text_len_for_layer=50, dpi=300):\n",
        "    all_text = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_index, page in enumerate(pdf.pages):\n",
        "            try:\n",
        "                text = page.extract_text()\n",
        "            except Exception as e:\n",
        "                print(f\"page.extract_text() error on page {page_index+1}: {e}\")\n",
        "                text = None\n",
        "\n",
        "            if (not text or len(text.strip()) < min_text_len_for_layer) and ocr_if_needed:\n",
        "                print(f\"Page {page_index+1}: Running OCR at {dpi} DPI...\")\n",
        "                try:\n",
        "                    page_image = page.to_image(resolution=dpi).original\n",
        "                except Exception as e:\n",
        "                    print(f\"page.to_image error fallback for page {page_index+1}: {e}\")\n",
        "                    page_image = page.to_image().original\n",
        "                page_image = preprocess_pil_image_for_ocr(page_image)\n",
        "                try:\n",
        "                    text = pytesseract.image_to_string(page_image, config=TESSERACT_COMMON_CONFIG)\n",
        "                except Exception as e:\n",
        "                    print(f\"Tesseract OCR failed on page {page_index+1}: {e}\")\n",
        "                    text = \"\"\n",
        "            if not text:\n",
        "                text = \"\"\n",
        "            all_text.append(f\"\\\\n--- PAGE {page_index+1} ---\\\\n{text}\")\n",
        "    return \"\\\\n\".join(all_text)\n",
        "\n",
        "def extract_text_from_docx(path):\n",
        "    try:\n",
        "        doc = docx.Document(path)\n",
        "        paragraphs = [p.text for p in doc.paragraphs if p.text and p.text.strip()]\n",
        "        return \"\\\\n\".join(paragraphs)\n",
        "    except Exception as e:\n",
        "        print(\"DOCX read error:\", e)\n",
        "        return \"\"\n",
        "\n",
        "def extract_text_from_image(path):\n",
        "    try:\n",
        "        img = Image.open(path)\n",
        "        img = preprocess_pil_image_for_ocr(img)\n",
        "        return pytesseract.image_to_string(img, config=TESSERACT_COMMON_CONFIG)\n",
        "    except Exception as e:\n",
        "        print(\"Image OCR error:\", e)\n",
        "        return \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "jSLKi2K6S-ol",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "jSLKi2K6S-ol",
        "outputId": "1b085f47-f859-4213-eff8-4baa2817e8e6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aaae0811-a336-4fed-af8e-9499c8594d74\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aaae0811-a336-4fed-af8e-9499c8594d74\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving embbedings.docx to embbedings.docx\n",
            "Uploaded: ['embbedings.docx']\n"
          ]
        }
      ],
      "source": [
        "# Upload files (Colab interactive)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "uploaded_filenames = list(uploaded.keys())\n",
        "print(\"Uploaded:\", uploaded_filenames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "Mkx6T-8MS-ol",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mkx6T-8MS-ol",
        "outputId": "012288bb-a25d-4607-843a-43879bc8b89e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote JSON: /content/doc_jsons/embbedings.json\n",
            "Total chunks prepared: 6\n"
          ]
        }
      ],
      "source": [
        "# Chunking, process files to JSON and prepare records\n",
        "def chunk_text(text, chunk_size=80, overlap=20):\n",
        "    tokens = text.split()\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(tokens):\n",
        "        chunk_tokens = tokens[i:i+chunk_size]\n",
        "        chunks.append(\" \".join(chunk_tokens))\n",
        "        i += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "def process_and_export(files_list):\n",
        "    records = []\n",
        "    for fname in files_list:\n",
        "        path = Path(fname)\n",
        "        ext = path.suffix.lower()\n",
        "        if ext == \".pdf\":\n",
        "            raw = extract_text_from_pdf(str(path))\n",
        "        elif ext in [\".docx\", \".doc\"]:\n",
        "            raw = extract_text_from_docx(str(path))\n",
        "        elif ext in [\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\", \".bmp\"]:\n",
        "            raw = extract_text_from_image(str(path))\n",
        "        else:\n",
        "            print(\"Skipping unsupported:\", fname)\n",
        "            continue\n",
        "\n",
        "        if not raw or len(raw.strip()) == 0:\n",
        "            print(\"No text extracted for:\", fname)\n",
        "            continue\n",
        "\n",
        "        metadata = {\"source_filename\": fname, \"id\": str(uuid.uuid4()), \"n_chars\": len(raw)}\n",
        "        chunks = chunk_text(raw, chunk_size=80, overlap=20)\n",
        "        doc_json = {\"metadata\": metadata, \"full_text\": raw, \"chunks\": []}\n",
        "        for idx, chunk in enumerate(chunks):\n",
        "            chunk_id = f\"{metadata['id']}_chunk_{idx}\"\n",
        "            doc_json[\"chunks\"].append({\"chunk_id\": chunk_id, \"text\": chunk, \"chunk_index\": idx})\n",
        "            records.append({\"id\": chunk_id, \"text\": chunk, \"metadata\": {**metadata, \"chunk_index\": idx}})\n",
        "        outpath = Path(JSON_OUTPUT_DIR) / (path.stem + \".json\")\n",
        "        with open(outpath, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(doc_json, f, ensure_ascii=False, indent=2)\n",
        "        print(\"Wrote JSON:\", outpath)\n",
        "    return records\n",
        "\n",
        "# Run processing on uploaded files\n",
        "records = process_and_export(uploaded_filenames)\n",
        "print(\"Total chunks prepared:\", len(records))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "A2M2rmoKS-ol",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2M2rmoKS-ol",
        "outputId": "a8d0c8a4-5970-4b4a-b8b5-aec2247a39f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Embedding: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings vectors: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load embedding model and create embeddings\n",
        "embed_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
        "texts = [r[\"text\"] for r in records]\n",
        "ids = [r[\"id\"] for r in records]\n",
        "metadatas = [r[\"metadata\"] for r in records]\n",
        "\n",
        "BATCH = 64\n",
        "embeddings = []\n",
        "for i in tqdm(range(0, len(texts), BATCH), desc=\"Embedding\"):\n",
        "    batch_texts = texts[i:i+BATCH]\n",
        "    embs = embed_model.encode(batch_texts, show_progress_bar=False, convert_to_numpy=True)\n",
        "    embeddings.extend(embs)\n",
        "print(\"Embeddings vectors:\", len(embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2HurUfuLS-ol",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HurUfuLS-ol",
        "outputId": "997f9845-71ba-4e44-e70a-a60c3295d871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chroma persisted at /content/chroma_db\n"
          ]
        }
      ],
      "source": [
        "# Create Chroma DB and insert vectors\n",
        "client = chromadb.PersistentClient(path=DB_DIR, settings=Settings())\n",
        "collection_name = \"customer_docs\"\n",
        "try:\n",
        "    collection = client.get_or_create_collection(collection_name)\n",
        "except Exception:\n",
        "    collection = client.create_collection(name=collection_name)\n",
        "\n",
        "# prepare embeddings to lists of floats (Chroma expects python floats)\n",
        "vecs = [e.tolist() if hasattr(e, \"tolist\") else list(map(float, e)) for e in embeddings]\n",
        "\n",
        "collection.add(ids=ids, metadatas=metadatas, documents=texts, embeddings=vecs)\n",
        "print(\"Chroma persisted at\", DB_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "gjmTROOxS-ol",
      "metadata": {
        "id": "gjmTROOxS-ol"
      },
      "outputs": [],
      "source": [
        "# Retrieval helper\n",
        "def search_chroma(query_text, top_k=3):\n",
        "    q_emb = embed_model.encode([query_text], convert_to_numpy=True)[0].astype(float).tolist()\n",
        "    results = collection.query(query_embeddings=[q_emb], n_results=top_k, include=[\"documents\",\"metadatas\",\"distances\"])\n",
        "    hits = []\n",
        "    for i in range(len(results[\"ids\"][0])):\n",
        "        hits.append({\n",
        "            \"id\": results[\"ids\"][0][i],\n",
        "            \"document\": results[\"documents\"][0][i],\n",
        "            \"metadata\": results[\"metadatas\"][0][i],\n",
        "            \"distance\": results[\"distances\"][0][i]\n",
        "        })\n",
        "    return hits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "MN2IRVRIS-om",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN2IRVRIS-om",
        "outputId": "1b5761f1-0c39-46e1-e8ef-f20cdbc9f57d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Load generation model (FLAN-T5) for RAG fusion\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Generation device:\", device)\n",
        "\n",
        "gen_tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL_NAME)\n",
        "gen_model = AutoModelForSeq2SeqLM.from_pretrained(GEN_MODEL_NAME).to(device)\n",
        "\n",
        "def tokenize_len(text):\n",
        "    return len(gen_tokenizer.encode(text, truncation=False))\n",
        "def truncate_context_by_tokens(chunks_texts, max_input_tokens, sep=\"\\n\\n---\\n\\n\"):\n",
        "    out = []\n",
        "    tokens = 0\n",
        "    for t in chunks_texts:\n",
        "        t_tokens = len(gen_tokenizer.encode(t + sep, truncation=False))\n",
        "        if tokens + t_tokens > max_input_tokens:\n",
        "            break\n",
        "        out.append(t)\n",
        "        tokens += t_tokens\n",
        "    return sep.join(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "Z2ghJkt2S-om",
      "metadata": {
        "id": "Z2ghJkt2S-om"
      },
      "outputs": [],
      "source": [
        "# Prompt template and RAG answer function\n",
        "PROMPT_SYSTEM = \"\"\"You are a helpful assistant. Answer the user question using ONLY the CONTEXT provided.\n",
        "If the context does not contain enough information to answer, respond: INSUFFICIENT_CONTEXT.\n",
        "Be concise (max ~120 words). Provide the answer and then list the sources (filename and chunk index).\"\"\"\n",
        "\n",
        "PROMPT_USER_TEMPLATE = \"\"\"\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUESTION:\n",
        "{question}\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1) Give a short direct answer (<120 words).\n",
        "2) After the answer print a \"SOURCES:\" section listing each source as - filename (chunk_index).\n",
        "3) If you can't answer from the context, respond exactly: INSUFFICIENT_CONTEXT\n",
        "4) Do not provide answers exactly in json format of in any strucutred manner, provide them in natural language by first processing it.\n",
        "\"\"\"\n",
        "\n",
        "def build_prompt(context, question):\n",
        "    return PROMPT_SYSTEM + \"\\n\\n\" + PROMPT_USER_TEMPLATE.format(context=context, question=question)\n",
        "\n",
        "def rag_answer(question, top_k=3, max_context_tokens=1500, max_answer_tokens=180):\n",
        "    # 1. Retrieve\n",
        "    hits = search_chroma(question, top_k=top_k)\n",
        "    if not hits:\n",
        "        return {\"question\": question, \"answer\": \"INSUFFICIENT_CONTEXT\", \"provenance\": [], \"used_context\": \"\"}\n",
        "\n",
        "    # 2. Build entries with provenance\n",
        "    entries = []\n",
        "    provenance = []\n",
        "    for h in hits:\n",
        "        src = h['metadata'].get('source_filename', 'unknown')\n",
        "        idx = h['metadata'].get('chunk_index', -1)\n",
        "        entry_text = f\"[{src} | chunk {idx}]\\n{h['document']}\"\n",
        "        entries.append(entry_text)\n",
        "        provenance.append({\"source\": src, \"chunk_index\": idx, \"distance\": h['distance'], \"id\": h['id']})\n",
        "\n",
        "    # 3. Truncate context to token budget\n",
        "    context = truncate_context_by_tokens(entries, max_context_tokens, sep=\"\\n\\n---\\n\\n\")\n",
        "    prompt = build_prompt(context, question)\n",
        "\n",
        "    # 4. Tokenize & generate\n",
        "    inputs = gen_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(device)\n",
        "    outputs = gen_model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_answer_tokens,\n",
        "        num_beams=4,\n",
        "        do_sample=False,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    answer = gen_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "\n",
        "    if not answer:\n",
        "        answer = \"INSUFFICIENT_CONTEXT\"\n",
        "\n",
        "    return {\"question\": question, \"answer\": answer, \"provenance\": provenance, \"used_context\": context}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d3fuIWaeS-om",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3fuIWaeS-om",
        "outputId": "f91ffc0b-d27e-4590-ebb5-117c4c100c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Optional: QA span extraction for exact fields\n",
        "qa_pipeline = pipeline(\"question-answering\", model=QA_MODEL_NAME, tokenizer=QA_MODEL_NAME, device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "def extract_exact_span(question, top_hit):\n",
        "    context = top_hit['document']\n",
        "    res = qa_pipeline(question=question, context=context, top_k=1)\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "E706mvpYS-om",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E706mvpYS-om",
        "outputId": "21fb8aeb-1ce2-40e3-8fd5-2106d9bc3980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HIT 1: embbedings.docx chunk 0\n",
            "{\\n \"borrower\": {\\n \"name\": \"JACK MERIDITH SPECTOR\",\\n \"social_security_number\": \"15-52-556\",\\n \"date_of_birth\": \"02/02/2000\",\\n \"citizenship\": \"U.S. Citizen\",\\n \"alternate_names\": [\"JACK MERIDITH SPECTOR\"],\\n \"marital_status\": \"Unmarried\",\\n \"dependents\": {\\n \"number\": 1,\\n \"ages\": [25]\\n },\\n \"contact_information\": {\\n \"home_phone\": \"252-252-3564\",\\n \"cell_phone\": \"252-252-6543\",\\n \"work_phone\": \"252-262-3654 x5635\",\\n \"email\": \"JACK@GMAIL.COM\"\\n },\\n \"current_address\": {\\n \"street\": \"BAKER'S \n",
            "distance: 1.1984632015228271\n",
            "-----\n",
            "\n",
            "HIT 2: embbedings.docx chunk 0\n",
            "{\\n \"borrower\": {\\n \"name\": \"JACK MERIDITH SPECTOR\",\\n \"social_security_number\": \"15-52-556\",\\n \"date_of_birth\": \"02/02/2000\",\\n \"citizenship\": \"U.S. Citizen\",\\n \"alternate_names\": [\"JACK MERIDITH SPECTOR\"],\\n \"marital_status\": \"Unmarried\",\\n \"dependents\": {\\n \"number\": 1,\\n \"ages\": [25]\\n },\\n \"contact_information\": {\\n \"home_phone\": \"252-252-3564\",\\n \"cell_phone\": \"252-252-6543\",\\n \"work_phone\": \"252-262-3654 x5635\",\\n \"email\": \"JACK@GMAIL.COM\"\\n },\\n \"current_address\": {\\n \"street\": \"BAKER'S \n",
            "distance: 1.1984633207321167\n",
            "-----\n",
            "\n",
            "HIT 3: embbedings.docx chunk 5\n",
            "\"loan_originator_information\": {\\n \"organization_name\": \"USA BANK\",\\n \"organization_address\": \"WALL STREET, NEW YORK, USA\",\\n \"organization_nmlsr_id\": \"25612DE23\",\\n \"organization_state_license\": \"SDFS5642\",\\n \"originator_name\": \"MAX VESTAPPEREN\",\\n \"originator_nmlsr_id\": \"DF23521\",\\n \"originator_state_license\": \"NY5623\",\\n \"email\": \"MAX@GMAIL.COM\",\\n \"phone\": \"231-568-9999\",\\n \"signature_date\": \"12/10/2025\"\\n }\\n}\n",
            "distance: 1.202184796333313\n",
            "-----\n",
            "\n",
            "ANSWER:\n",
            " 15-52-556\n",
            "\n",
            "PROVENANCE:\n",
            " [{'source': 'embbedings.docx', 'chunk_index': 0, 'distance': 1.1984632015228271, 'id': '941308fb-ee47-44a3-8fe4-30cddf524581_chunk_0'}, {'source': 'embbedings.docx', 'chunk_index': 0, 'distance': 1.1984633207321167, 'id': '286074e1-4d7d-4ce0-a72c-a236ae5831e9_chunk_0'}, {'source': 'embbedings.docx', 'chunk_index': 5, 'distance': 1.202184796333313, 'id': '286074e1-4d7d-4ce0-a72c-a236ae5831e9_chunk_5'}]\n",
            "\n",
            "Exact span extracted by QA model: {'score': 0.8772997260093689, 'start': 82, 'end': 91, 'answer': '15-52-556'}\n"
          ]
        }
      ],
      "source": [
        "# Examples / Usage\n",
        "\n",
        "# Retrieval-only example:\n",
        "q = \"What is the borrower’s Social Security Number?\"\n",
        "hits = search_chroma(q, top_k=3)\n",
        "for i,h in enumerate(hits,1):\n",
        "    print(f\"HIT {i}: {h['metadata']['source_filename']} chunk {h['metadata']['chunk_index']}\")\n",
        "    print(h['document'][:500].replace(\"\\n\",\" \"))\n",
        "    print(\"distance:\", h['distance'])\n",
        "    print(\"-----\\n\")\n",
        "\n",
        "# RAG: generate concise, grounded answer\n",
        "out = rag_answer(q, top_k=3)\n",
        "print(\"ANSWER:\\n\", out[\"answer\"])\n",
        "print(\"\\nPROVENANCE:\\n\", out[\"provenance\"])\n",
        "\n",
        "# Optional: exact span from top hit\n",
        "if hits:\n",
        "    span = extract_exact_span(q, hits[0])\n",
        "    print(\"\\nExact span extracted by QA model:\", span)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Examples / Usage\n",
        "\n",
        "# Retrieval-only example:\n",
        "q = \"What is the borrower’s base income?\"\n",
        "hits = search_chroma(q, top_k=3)\n",
        "for i,h in enumerate(hits,1):\n",
        "    print(f\"HIT {i}: {h['metadata']['source_filename']} chunk {h['metadata']['chunk_index']}\")\n",
        "    print(h['document'][:500].replace(\"\\n\",\" \"))\n",
        "    print(\"distance:\", h['distance'])\n",
        "    print(\"-----\\n\")\n",
        "\n",
        "# RAG: generate concise, grounded answer\n",
        "out = rag_answer(q, top_k=3)\n",
        "print(\"ANSWER:\\n\", out[\"answer\"])\n",
        "print(\"\\nPROVENANCE:\\n\", out[\"provenance\"])\n",
        "\n",
        "# Optional: exact span from top hit\n",
        "if hits:\n",
        "    span = extract_exact_span(q, hits[0])\n",
        "    print(\"\\nExact span extracted by QA model:\", span)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLSNjYqvpyme",
        "outputId": "7ca38b29-28d5-4756-e9da-33f06b11835e"
      },
      "id": "fLSNjYqvpyme",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HIT 1: embbedings.docx chunk 1\n",
            "\"1 year\",\\n \"employed_by_family_member\": false,\\n \"income\": {\\n \"base\": 50000,\\n \"overtime\": 2000,\\n \"bonus\": 1000,\\n \"commission\": 0,\\n \"military_entitlements\": 20000,\\n \"other\": 0,\\n \"monthly_total_income\": 73000\\n }\\n }\\n },\\n \"assets\": {\\n \"bank_and_investment_accounts\": [\\n {\\n \"type\": \"Individual Development Account\",\\n \"institution\": \"USA1\",\\n \"value\": 10000\\n },\\n {\\n \"type\": \"Cash Value of Life Insurance\",\\n \"institution\": \"LIC\",\\n \"value\": 20000\\n }\\n ],\\n \"total_asset_value\": 30000\\n \n",
            "distance: 1.3143130540847778\n",
            "-----\n",
            "\n",
            "HIT 2: embbedings.docx chunk 5\n",
            "\"loan_originator_information\": {\\n \"organization_name\": \"USA BANK\",\\n \"organization_address\": \"WALL STREET, NEW YORK, USA\",\\n \"organization_nmlsr_id\": \"25612DE23\",\\n \"organization_state_license\": \"SDFS5642\",\\n \"originator_name\": \"MAX VESTAPPEREN\",\\n \"originator_nmlsr_id\": \"DF23521\",\\n \"originator_state_license\": \"NY5623\",\\n \"email\": \"MAX@GMAIL.COM\",\\n \"phone\": \"231-568-9999\",\\n \"signature_date\": \"12/10/2025\"\\n }\\n}\n",
            "distance: 1.3708488941192627\n",
            "-----\n",
            "\n",
            "HIT 3: embbedings.docx chunk 3\n",
            "\"credit_cards_and_loans\": [],\\n \"other_liabilities_expenses\": []\\n },\\n \"real_estate\": {\\n \"owns_real_estate\": false\\n },\\n \"loan_information\": {\\n \"loan_amount\": 200000,\\n \"loan_purpose\": \"Purchase\",\\n \"property\": {\\n \"address\": {\\n \"street\": \"BAKERS STREET\",\\n \"unit\": \"5\",\\n \"city\": \"NEW YORK\",\\n \"state\": \"NC\",\\n \"zip\": \"12563\",\\n \"country\": \"USA\"\\n },\\n \"value\": 500000,\\n \"number_of_units\": 55,\\n \"occupancy_type\": \"Second Home\",\\n \"mixed_use_property\": true,\\n \"manufactured_home\": false\\n },\\\n",
            "distance: 1.4021720886230469\n",
            "-----\n",
            "\n",
            "ANSWER:\n",
            " 50000\n",
            "\n",
            "PROVENANCE:\n",
            " [{'source': 'embbedings.docx', 'chunk_index': 1, 'distance': 1.3143130540847778, 'id': '941308fb-ee47-44a3-8fe4-30cddf524581_chunk_1'}, {'source': 'embbedings.docx', 'chunk_index': 5, 'distance': 1.3708488941192627, 'id': '286074e1-4d7d-4ce0-a72c-a236ae5831e9_chunk_5'}, {'source': 'embbedings.docx', 'chunk_index': 3, 'distance': 1.4021720886230469, 'id': '286074e1-4d7d-4ce0-a72c-a236ae5831e9_chunk_3'}]\n",
            "\n",
            "Exact span extracted by QA model: {'score': 0.9390794654464116, 'start': 72, 'end': 77, 'answer': '50000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Examples / Usage\n",
        "\n",
        "# Retrieval-only example:\n",
        "q = \"What is the total monthly income?\"\n",
        "hits = search_chroma(q, top_k=3)\n",
        "for i,h in enumerate(hits,1):\n",
        "    print(f\"HIT {i}: {h['metadata']['source_filename']} chunk {h['metadata']['chunk_index']}\")\n",
        "    print(h['document'][:500].replace(\"\\n\",\" \"))\n",
        "    print(\"distance:\", h['distance'])\n",
        "    print(\"-----\\n\")\n",
        "\n",
        "# RAG: generate concise, grounded answer\n",
        "out = rag_answer(q, top_k=3)\n",
        "print(\"ANSWER:\\n\", out[\"answer\"])\n",
        "print(\"\\nPROVENANCE:\\n\", out[\"provenance\"])\n",
        "\n",
        "# Optional: exact span from top hit\n",
        "if hits:\n",
        "    span = extract_exact_span(q, hits[0])\n",
        "    print(\"\\nExact span extracted by QA model:\", span)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYonxvINteBY",
        "outputId": "c4ac9c18-51fd-4c68-c7cf-206ba9475a31"
      },
      "id": "VYonxvINteBY",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HIT 1: embbedings.docx chunk 2\n",
            "\"position\": \"MANAGER\",\\n \"start_date\": \"02/02/2020\",\\n \"experience\": \"1 year\",\\n \"employed_by_family_member\": false,\\n \"income\": {\\n \"base\": 50000,\\n \"overtime\": 2000,\\n \"bonus\": 1000,\\n \"commission\": 0,\\n \"military_entitlements\": 20000,\\n \"other\": 0,\\n \"monthly_total_income\": 73000\\n }\\n }\\n },\\n \"assets\": {\\n \"bank_and_investment_accounts\": [\\n {\\n \"type\": \"Individual Development Account\",\\n \"institution\": \"USA1\",\\n \"value\": 10000\\n },\\n {\\n \"type\": \"Cash Value of Life Insurance\",\\n \"instituti\n",
            "distance: 1.245530366897583\n",
            "-----\n",
            "\n",
            "HIT 2: embbedings.docx chunk 1\n",
            "\"1 year\",\\n \"employed_by_family_member\": false,\\n \"income\": {\\n \"base\": 50000,\\n \"overtime\": 2000,\\n \"bonus\": 1000,\\n \"commission\": 0,\\n \"military_entitlements\": 20000,\\n \"other\": 0,\\n \"monthly_total_income\": 73000\\n }\\n }\\n },\\n \"assets\": {\\n \"bank_and_investment_accounts\": [\\n {\\n \"type\": \"Individual Development Account\",\\n \"institution\": \"USA1\",\\n \"value\": 10000\\n },\\n {\\n \"type\": \"Cash Value of Life Insurance\",\\n \"institution\": \"LIC\",\\n \"value\": 20000\\n }\\n ],\\n \"total_asset_value\": 30000\\n \n",
            "distance: 1.3244422674179077\n",
            "-----\n",
            "\n",
            "HIT 3: embbedings.docx chunk 1\n",
            "\"housing_status\": \"Own\"\\n },\\n \"former_address\": {\\n \"street\": \"BAKER'S STREET\",\\n \"unit\": \"5\",\\n \"city\": \"NEW YORK\",\\n \"state\": \"NC\",\\n \"zip\": \"12563\",\\n \"country\": \"USA\"\\n },\\n \"mailing_address\": {\\n \"street\": \"BAKER'S STREET\",\\n \"unit\": \"5\",\\n \"city\": \"NEW YORK\",\\n \"state\": \"NC\",\\n \"zip\": \"12563\",\\n \"country\": \"USA\"\\n }\\n },\\n \"employment\": {\\n \"current_employment\": {\\n \"employer\": \"AMAZON\",\\n \"street\": \"MARY STREET\",\\n \"unit\": \"45\",\\n \"city\": \"NEW YORK\",\\n \"state\": \"NC\",\\n \"zip\": \"12599\",\\n \n",
            "distance: 1.4171435832977295\n",
            "-----\n",
            "\n",
            "ANSWER:\n",
            " 73000\n",
            "\n",
            "PROVENANCE:\n",
            " [{'source': 'embbedings.docx', 'chunk_index': 2, 'distance': 1.245530366897583, 'id': '286074e1-4d7d-4ce0-a72c-a236ae5831e9_chunk_2'}, {'source': 'embbedings.docx', 'chunk_index': 1, 'distance': 1.3244422674179077, 'id': '941308fb-ee47-44a3-8fe4-30cddf524581_chunk_1'}, {'source': 'embbedings.docx', 'chunk_index': 1, 'distance': 1.4171435832977295, 'id': '286074e1-4d7d-4ce0-a72c-a236ae5831e9_chunk_1'}]\n",
            "\n",
            "Exact span extracted by QA model: {'score': 0.8562769145937636, 'start': 278, 'end': 283, 'answer': '73000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Examples / Usage\n",
        "\n",
        "# Retrieval-only example:\n",
        "q = \"What is the total asset value?\"\n",
        "hits = search_chroma(q, top_k=3)\n",
        "for i,h in enumerate(hits,1):\n",
        "    print(f\"HIT {i}: {h['metadata']['source_filename']} chunk {h['metadata']['chunk_index']}\")\n",
        "    print(h['document'][:500].replace(\"\\n\",\" \"))\n",
        "    print(\"distance:\", h['distance'])\n",
        "    print(\"-----\\n\")\n",
        "\n",
        "# RAG: generate concise, grounded answer\n",
        "out = rag_answer(q, top_k=3)\n",
        "print(\"ANSWER:\\n\", out[\"answer\"])\n",
        "print(\"\\nPROVENANCE:\\n\", out[\"provenance\"])\n",
        "\n",
        "# Optional: exact span from top hit\n",
        "if hits:\n",
        "    span = extract_exact_span(q, hits[0])\n",
        "    print(\"\\nExact span extracted by QA model:\", span)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzpo53mdtlbv",
        "outputId": "78b30999-503b-435e-b21c-46b79e0b967c"
      },
      "id": "dzpo53mdtlbv",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HIT 1: embbedings.docx chunk 2\n",
            "\"position\": \"MANAGER\",\\n \"start_date\": \"02/02/2020\",\\n \"experience\": \"1 year\",\\n \"employed_by_family_member\": false,\\n \"income\": {\\n \"base\": 50000,\\n \"overtime\": 2000,\\n \"bonus\": 1000,\\n \"commission\": 0,\\n \"military_entitlements\": 20000,\\n \"other\": 0,\\n \"monthly_total_income\": 73000\\n }\\n }\\n },\\n \"assets\": {\\n \"bank_and_investment_accounts\": [\\n {\\n \"type\": \"Individual Development Account\",\\n \"institution\": \"USA1\",\\n \"value\": 10000\\n },\\n {\\n \"type\": \"Cash Value of Life Insurance\",\\n \"instituti\n",
            "distance: 1.196429967880249\n",
            "-----\n",
            "\n",
            "HIT 2: embbedings.docx chunk 1\n",
            "\"1 year\",\\n \"employed_by_family_member\": false,\\n \"income\": {\\n \"base\": 50000,\\n \"overtime\": 2000,\\n \"bonus\": 1000,\\n \"commission\": 0,\\n \"military_entitlements\": 20000,\\n \"other\": 0,\\n \"monthly_total_income\": 73000\\n }\\n }\\n },\\n \"assets\": {\\n \"bank_and_investment_accounts\": [\\n {\\n \"type\": \"Individual Development Account\",\\n \"institution\": \"USA1\",\\n \"value\": 10000\\n },\\n {\\n \"type\": \"Cash Value of Life Insurance\",\\n \"institution\": \"LIC\",\\n \"value\": 20000\\n }\\n ],\\n \"total_asset_value\": 30000\\n \n",
            "distance: 1.2140611410140991\n",
            "-----\n",
            "\n",
            "HIT 3: embbedings.docx chunk 3\n",
            "\"credit_cards_and_loans\": [],\\n \"other_liabilities_expenses\": []\\n },\\n \"real_estate\": {\\n \"owns_real_estate\": false\\n },\\n \"loan_information\": {\\n \"loan_amount\": 200000,\\n \"loan_purpose\": \"Purchase\",\\n \"property\": {\\n \"address\": {\\n \"street\": \"BAKERS STREET\",\\n \"unit\": \"5\",\\n \"city\": \"NEW YORK\",\\n \"state\": \"NC\",\\n \"zip\": \"12563\",\\n \"country\": \"USA\"\\n },\\n \"value\": 500000,\\n \"number_of_units\": 55,\\n \"occupancy_type\": \"Second Home\",\\n \"mixed_use_property\": true,\\n \"manufactured_home\": false\\n },\\\n",
            "distance: 1.3899924755096436\n",
            "-----\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSWER:\n",
            " 30000\n",
            "\n",
            "PROVENANCE:\n",
            " [{'source': 'embbedings.docx', 'chunk_index': 2, 'distance': 1.196429967880249, 'id': '286074e1-4d7d-4ce0-a72c-a236ae5831e9_chunk_2'}, {'source': 'embbedings.docx', 'chunk_index': 1, 'distance': 1.2140611410140991, 'id': '941308fb-ee47-44a3-8fe4-30cddf524581_chunk_1'}, {'source': 'embbedings.docx', 'chunk_index': 3, 'distance': 1.3899924755096436, 'id': '286074e1-4d7d-4ce0-a72c-a236ae5831e9_chunk_3'}]\n",
            "\n",
            "Exact span extracted by QA model: {'score': 0.8957427574787289, 'start': 561, 'end': 566, 'answer': '30000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FwiwJIc_S-om",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwiwJIc_S-om",
        "outputId": "ef064e64-d328-462c-8adb-72590fd38cb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zipped at /content/chroma_db.zip and /content/doc_jsons.zip\n"
          ]
        }
      ],
      "source": [
        "# Save DB and JSONs for download (optional)\n",
        "!zip -r -q /content/chroma_db.zip /content/chroma_db\n",
        "!zip -r -q /content/doc_jsons.zip /content/doc_jsons\n",
        "print(\"Zipped at /content/chroma_db.zip and /content/doc_jsons.zip\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}